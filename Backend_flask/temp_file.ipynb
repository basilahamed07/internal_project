{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\basilahamed.h\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    " !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basil</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hello</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>somting</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         3\n",
       "basil     \n",
       "hello    3\n",
       "somting  4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df = pd.read_excel('SaleData.xlsx')\n",
    "# # print(df)\n",
    "\n",
    "# df[\"new_values\"] = df.groupby([\"Item\"]).aggregate({\"Unit_price\": \"sum\"}).reset_index()[\"Unit_price\"]\n",
    "\n",
    "# df\n",
    "\n",
    "\n",
    "\n",
    "file = 'SaleData.xlsx'\n",
    "sheet1 = pd.read_excel(file, \n",
    "                        sheet_name = \"data_one\", \n",
    "                        index_col = 2)\n",
    "sheet2 = pd.read_excel(file, \n",
    "                        sheet_name = \"sample_data\", \n",
    "                        index_col = 0)\n",
    "\n",
    "# sheet2 = pd.read_excel(file, \n",
    "#                         sheet_name = 1, \n",
    "#                         index_col = 0)\n",
    "\n",
    "# concatinating both the sheets\n",
    "# newData = pd.concat([sheet1, sheet2])\n",
    "# print(newData)\n",
    "\n",
    "sheet1\n",
    "sheet2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Using cached et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Using cached et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"GROQ_API_KEY\"):\n",
    "  os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter API key for Groq: \")\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'export' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!export GROQ_API_KEY=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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(\"postgresql://postgres:database@localhost/internal_project\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[QuerySQLDatabaseTool(description=\"Input to this tool is a detailed and correct SQL query, output is a result from the database. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', use sql_db_schema to query the correct table fields.\", db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x000001396D8FA960>),\n",
       " InfoSQLDatabaseTool(description='Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. Be sure that the tables actually exist by calling sql_db_list_tables first! Example Input: table1, table2, table3', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x000001396D8FA960>),\n",
       " ListSQLDatabaseTool(db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x000001396D8FA960>),\n",
       " QuerySQLCheckerTool(description='Use this tool to double check if your query is correct before executing it. Always use this tool before executing a query with sql_db_query!', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x000001396D8FA960>, llm=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001396B83A870>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001396B83B350>, model_name='llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['dialect', 'query'], input_types={}, partial_variables={}, template='\\n{query}\\nDouble check the {dialect} query above for common mistakes, including:\\n- Using NOT IN with NULL values\\n- Using UNION when UNION ALL should have been used\\n- Using BETWEEN for exclusive ranges\\n- Data type mismatch in predicates\\n- Properly quoting identifiers\\n- Using the correct number of arguments for functions\\n- Casting to the correct data type\\n- Using the proper columns for joins\\n\\nIf there are any of the above mistakes, rewrite the query. If there are no mistakes, just reproduce the original query.\\n\\nOutput the final SQL query only.\\n\\nSQL Query: '), llm=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001396B83A870>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001396B83B350>, model_name='llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toolkit.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\SIX-DATA\\six_data_jira\\vizualation\\Lib\\site-packages\\langsmith\\client.py:256: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dialect', 'top_k']\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt_template = hub.pull(\"langchain-ai/sql-agent-system-prompt\")\n",
    "\n",
    "assert len(prompt_template.messages) == 1\n",
    "print(prompt_template.input_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.sql_database.tool import (\n",
    "    InfoSQLDatabaseTool,\n",
    "    ListSQLDatabaseTool,\n",
    "    QuerySQLCheckerTool,\n",
    "    QuerySQLDatabaseTool,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = prompt_template.format(dialect=\"SQLite\", top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent_executor = create_react_agent(\n",
    "    llm, toolkit.get_tools(), state_modifier=system_message\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph\n",
      "  Downloading langgraph-0.2.60-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in d:\\six-data\\six_data_jira\\vizualation\\lib\\site-packages (from langgraph) (0.3.28)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.4 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.0.9-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.1.48-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\six-data\\six_data_jira\\vizualation\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\six-data\\six_data_jira\\vizualation\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in d:\\six-data\\six_data_jira\\vizualation\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.2.7)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in d:\\six-data\\six_data_jira\\vizualation\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\six-data\\six_data_jira\\vizualation\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.10.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\six-data\\six_data_jira\\vizualation\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\six-data\\six_data_jira\\vizualation\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (4.12.2)\n",
      "Collecting msgpack<2.0.0,>=1.1.0 (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph)\n",
      "  Using cached msgpack-1.1.0-cp312-cp312-win_amd64.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in d:\\six-data\\six_data_jira\\vizualation\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in d:\\six-data\\six_data_jira\\vizualation\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.13)\n",
      "Requirement already satisfied: anyio in d:\\six-data\\six_data_jira\\vizualation\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.7.0)\n",
      "Requirement already satisfied: certifi in d:\\six-data\\six_data_jira\\vizualation\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\six-data\\six_data_jira\\vizualation\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
      "Requirement already satisfied: idna in d:\\six-data\\six_data_jira\\vizualation\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\six-data\\six_data_jira\\vizualation\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\six-data\\six_data_jira\\vizualation\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\six-data\\six_data_jira\\vizualation\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\six-data\\six_data_jira\\vizualation\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\six-data\\six_data_jira\\vizualation\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\six-data\\six_data_jira\\vizualation\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\six-data\\six_data_jira\\vizualation\\lib\\site-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\six-data\\six_data_jira\\vizualation\\lib\\site-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.2.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\six-data\\six_data_jira\\vizualation\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
      "Downloading langgraph-0.2.60-py3-none-any.whl (135 kB)\n",
      "   ---------------------------------------- 0.0/135.7 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 61.4/135.7 kB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  133.1/135.7 kB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  133.1/135.7 kB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  133.1/135.7 kB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- 135.7/135.7 kB 729.5 kB/s eta 0:00:00\n",
      "Downloading langgraph_checkpoint-2.0.9-py3-none-any.whl (37 kB)\n",
      "Downloading langgraph_sdk-0.1.48-py3-none-any.whl (43 kB)\n",
      "   ---------------------------------------- 0.0/43.7 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 41.0/43.7 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 41.0/43.7 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 41.0/43.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 43.7/43.7 kB 212.8 kB/s eta 0:00:00\n",
      "Using cached msgpack-1.1.0-cp312-cp312-win_amd64.whl (75 kB)\n",
      "Installing collected packages: msgpack, langgraph-sdk, langgraph-checkpoint, langgraph\n",
      "Successfully installed langgraph-0.2.60 langgraph-checkpoint-2.0.9 langgraph-sdk-0.1.48 msgpack-1.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "system_message = prompt_template.format(dialect=\"SQLite\", top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "if basil was present ?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_list_tables (call_9qse)\n",
      " Call ID: call_9qse\n",
      "  Args:\n",
      "    tool_input: \n",
      "  sql_db_schema (call_xffz)\n",
      " Call ID: call_xffz\n",
      "  Args:\n",
      "    table_names: table1, table2, table3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_schema\n",
      "\n",
      "Error: table_names {'table2', 'table1', 'table3'} not found in database\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_query (call_p3xx)\n",
      " Call ID: call_p3xx\n",
      "  Args:\n",
      "    query: SELECT * FROM testers WHERE project_name='?'\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_query\n",
      "\n",
      "Error: (psycopg2.errors.UndefinedColumn) column \"project_name\" does not exist\n",
      "LINE 1: SELECT * FROM testers WHERE project_name='?'\n",
      "                                    ^\n",
      "HINT:  Perhaps you meant to reference the column \"testers.project_name_id\".\n",
      "\n",
      "[SQL: SELECT * FROM testers WHERE project_name='?']\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_query_checker (call_8bmv)\n",
      " Call ID: call_8bmv\n",
      "  Args:\n",
      "    query: SELECT * FROM testers\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_query_checker\n",
      "\n",
      "There are no mistakes in the provided query. The query is simply selecting all columns (`*`) from a table named \"testers\".\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_query (call_977b)\n",
      " Call ID: call_977b\n",
      "  Args:\n",
      "    query: SELECT project_name FROM testers LIMIT 5\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_query\n",
      "\n",
      "Error: (psycopg2.errors.UndefinedColumn) column \"project_name\" does not exist\n",
      "LINE 1: SELECT project_name FROM testers LIMIT 5\n",
      "               ^\n",
      "HINT:  Perhaps you meant to reference the column \"testers.project_name_id\".\n",
      "\n",
      "[SQL: SELECT project_name FROM testers LIMIT 5]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_schema (call_g5dv)\n",
      " Call ID: call_g5dv\n",
      "  Args:\n",
      "    table_names: testers\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_schema\n",
      "\n",
      "\n",
      "CREATE TABLE testers (\n",
      "\tid SERIAL NOT NULL, \n",
      "\tbillable BOOLEAN, \n",
      "\ttester_name_id INTEGER NOT NULL, \n",
      "\tproject_name_id INTEGER NOT NULL, \n",
      "\tuser_id INTEGER NOT NULL, \n",
      "\tCONSTRAINT testers_pkey PRIMARY KEY (id), \n",
      "\tCONSTRAINT testers_project_name_id_fkey FOREIGN KEY(project_name_id) REFERENCES project_name (id), \n",
      "\tCONSTRAINT testers_tester_name_id_fkey FOREIGN KEY(tester_name_id) REFERENCES \"Tester_name\" (id), \n",
      "\tCONSTRAINT testers_user_id_fkey FOREIGN KEY(user_id) REFERENCES users (id)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from testers table:\n",
      "id\tbillable\ttester_name_id\tproject_name_id\tuser_id\n",
      "76\tTrue\t25\t161\t4\n",
      "77\tTrue\t26\t161\t4\n",
      "78\tFalse\t13\t161\t4\n",
      "*/\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_query (call_mqw7)\n",
      " Call ID: call_mqw7\n",
      "  Args:\n",
      "    query: SELECT DISTINCT project_name_id FROM testers LIMIT 5\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_query\n",
      "\n",
      "[(161,)]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The project name is 161.\n"
     ]
    }
   ],
   "source": [
    "example_query = \"if basil was present ?\"\n",
    "\n",
    "events = agent_executor.stream(\n",
    "    {\"messages\": [(\"user\", example_query)]},\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.parse\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from langchain_community.llms import OpenAI\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit\n",
    "from langchain_community.agent_toolkits.sql.base import create_sql_agent\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    FewShotPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langsmith import traceable\n",
    "from urllib.parse import quote_plus\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import Tool\n",
    "from sqlalchemy import create_engine\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Initialize Flask App\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "required_env_vars = [\"LANGCHAIN_API_KEY\"]\n",
    "missing_vars = [var for var in required_env_vars if not os.getenv(var)]\n",
    "if missing_vars:\n",
    "    raise ValueError(f\"Missing required environment variables: {', '.join(missing_vars)}\")\n",
    "\n",
    "# Set up OpenAI API key\n",
    "os.environ[\"OPENAI_API_TYPE\"] = os.getenv(\"AZURE_OPENAI_API_TYPE\")\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "os.environ['LANGCHAIN_TRACING_V2']='true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] =\"https://api.smith.langchain.com\"\n",
    "os.environ['LANGCHAIN_API_KEY'] =os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ['LANGCHAIN_PROJECT']=\"new1\"\n",
    "# Database configuration\n",
    "# DB_CONFIG = {\n",
    "#     \"host\": os.getenv(\"DB_HOST\", \"localhost\"),\n",
    "#     \"port\": os.getenv(\"DB_PORT\", \"5432\"),  # Default PostgreSQL port\n",
    "#     \"username\": os.getenv(\"DB_USERNAME\", \"postgres\"),\n",
    "#     \"password\": os.getenv(\"DB_PASSWORD\", 'Database@123'),\n",
    "#     \"database\": os.getenv(\"DB_NAME\", \"AES_Mini\"),\n",
    "# }\n",
    "\n",
    "# # Ensure password and other sensitive info are encoded\n",
    "# encoded_password = urllib.parse.quote(DB_CONFIG[\"password\"])\n",
    "\n",
    "# Connection string\n",
    "# DATABASE_URL = (\n",
    "#     f\"postgresql+psycopg2://{DB_CONFIG['username']}:{encoded_password}\"\n",
    "#     f\"@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "# )\n",
    "\n",
    "server = os.getenv(\"SQL_SERVER_HOST\")\n",
    "database = os.getenv(\"SQL_SERVER_DB\")\n",
    "username = os.getenv(\"SQL_SERVER_USER\")\n",
    "password = os.getenv(\"SQL_SERVER_PASSWORD\")\n",
    "\n",
    "DATABASE_URL = (\n",
    "    f\"mssql+pyodbc://{username}:{password}@{server}/{database}\"\n",
    "    f\"?driver=ODBC Driver 17 for SQL Server\"\n",
    ")\n",
    "# Check database connection\n",
    "try:\n",
    "    engine = create_engine(DATABASE_URL)\n",
    "    with engine.connect() as connection:\n",
    "        print(\"Connection successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to connect to the database: {e}\")\n",
    "\n",
    "# Create an instance of SQLDatabase\n",
    "db = SQLDatabase.from_uri(DATABASE_URL)\n",
    "\n",
    "# Initialize LangChain LLM\n",
    "llm = AzureChatOpenAI(\n",
    "            deployment_name=\"gpt-4o\",\n",
    "            model_name=\"gpt-4o\"\n",
    "        )\n",
    "\n",
    "# Decide table and column function\n",
    "\n",
    "def decide_table_column(query):\n",
    "    \"\"\"Decide which table and column will answer the query of the user.\"\"\"\n",
    "    with open('table_column_description.txt', 'r') as file:\n",
    "        file_content = file.read()\n",
    "\n",
    "    template = f\"\"\"\n",
    "    Based on the given user query: \"{query}\", return the table names and column names which will fetch the data from the database.\n",
    "    If multiple tables are required to respond to the user query, select appropriate columns from different tables to form appropriate JOINs.\n",
    "    Table and column descriptions are given here:\n",
    "    {file_content}\n",
    "    \"\"\"\n",
    "    prompt_template = ChatPromptTemplate.from_template(template)\n",
    "    prompt = prompt_template.invoke({\"query\": query, \"file_content\": file_content})\n",
    "    result = llm.invoke(prompt)\n",
    "    return result.content\n",
    "\n",
    "# Create a custom tool for deciding table and column\n",
    "custom_tool = Tool(\n",
    "    name=\"decide_table_column\",\n",
    "    func=decide_table_column,\n",
    "    description=\"Decides which tables and columns answer the user's query, and determines joins between tables if required.\",\n",
    ")\n",
    "\n",
    "# Prompt structure for SQL generation\n",
    "\n",
    "system_prefix = \"\"\"You are an AI agent designed to interact with a SQL database to answer questions by querying specific tables and columns based on the provided schema information.\n",
    "\n",
    "Given an input question, construct a syntactically correct SQL query based on the table and column descriptions. Retrieve the necessary information from the tables to provide an accurate answer. Ensure that the query is contextually relevant to the input question and adheres to the following guidelines:\n",
    "\n",
    "1. Query Structure:\n",
    "   - Avoid selecting all columns; only include relevant columns based on the question.\n",
    "   - Limit results to the necessary records to maintain efficient queries.\n",
    "   - Ensure that your queries do not contain DML statements (such as `INSERT`, `UPDATE`, `DELETE`, or `DROP`).\n",
    "   \n",
    "2. Error Handling:\n",
    "   - Double-check the query syntax before execution.\n",
    "   - If an error occurs during execution, rewrite the query based on error feedback and try again.\n",
    "\n",
    "3. Question Types:\n",
    "   - Any question related to 'Index Performance Summary' comes in, in response data of MTD, QTD and YTD is expected.\n",
    "   - MTD stands for “month to date.” It’s the period starting from the beginning of the current month up until now … but not including today’s date, because it might not be complete yet.\n",
    "   - QTD stands for “quarter to date.” It’s used in exactly the same way as MTD, except you’re looking at the time period from the start of this quarter until now.\n",
    "   - YTD stands for “year to date” — again, from the beginning of the current year, up to but not including today.\n",
    "   - For percentage data, please provide valuation in percentage example: 25.5%\n",
    "Here are some example user inputs and their corresponding SQL queries:\n",
    "\"\"\"\n",
    "system_suffix = \"\"\"\n",
    "When providing the final answer:\n",
    "\n",
    "1. Contextualize: Summarize the information retrieved in a way that directly addresses the user's question. Provide concise, relevant answers instead of just returning raw query results.\n",
    "2. Clarify Ambiguity: If the retrieved information does not directly answer the question, explain the context or suggest potential follow-up queries to refine the result.\n",
    "3. Error Responses: If a query cannot be executed due to a syntax or data issue, respond with a clear message, like \"The requested information could not be retrieved due to a query error. Please refine your question.\"\n",
    "4. Unknown Queries: If the question is outside the scope of the database tables or cannot be answered with available data, respond with \"I don't know.\"\n",
    "\n",
    "Answer concisely and clearly, ensuring accuracy and relevance to the user's question.\n",
    "\"\"\"\n",
    "examples = [\n",
    "    {\"input\": \"Show me the valuation types available.\", \"query\": \"SELECT ValuationType FROM ValuationTypeTable;\"},\n",
    "    {\"input\": \"show top 3 index performance summary with Month to Date(MTD) as on 31-oct-2024?\", \"query\": \"DECLARE @qtdDate DATETIME = '2024-10-01'; SELECT TOP 5 mi.FundName, mi.MarketIndexId, EXP(SUM(CASE WHEN v.ValuationDate = EOMONTH(v.ValuationDate) THEN LOG(NULLIF(1 + v.Value / 100, 0)) END)) - 1 AS QTD_Performance FROM Valuations v JOIN MarketIndex mi ON v.EntityId = mi.MarketIndexId WHERE v.EntityTypeId = 3 AND v.ValuationDate >= @qtdDate AND v.FrequencyId = 3 GROUP BY mi.FundName, mi.MarketIndexId ORDER BY QTD_Performance DESC;\"},\n",
    "    {\"input\": \"get the index performance summary as on 01-10-2024.\", \n",
    "     \"query\": \"\"\"DECLARE @qtdDate DATETIME = '2024-10-01'; SELECT TOP 5 mi.MarketIndexName, v.EntityId AS MarketIndexId,\n",
    "            EXP(SUM(CASE WHEN v.ValuationDate = EOMONTH(v.ValuationDate) THEN LOG(NULLIF(1 + v.Value / 100, 0)) END)) - 1 AS QTD_Performance \n",
    "            FROM AES_Mini.dbo.Valuations v JOIN AES_Mini.dbo.MarketIndex mi ON v.EntityId = mi.MarketIndexId WHERE v.EntityTypeId = 3 AND v.ValuationDate >= @qtdDate AND v.FrequencyId = 3 \n",
    "            GROUP BY mi.MarketIndexName, v.EntityId \n",
    "            ORDER BY QTD_Performance DESC;\"\"\"},\n",
    "    {\"input\": \"give me top 5 index performance summary\",\n",
    "    \"query\": \"\"\"SELECT TOP 5 mi.MarketIndexName, v.EntityId AS MarketIndexId,\n",
    "            EXP(SUM(CASE WHEN v.ValuationDate = EOMONTH(v.ValuationDate) THEN LOG(NULLIF(1 + v.Value / 100, 0)) END)) - 1 AS QTD_Performance \n",
    "            FROM AES_Mini.dbo.Valuations v JOIN AES_Mini.dbo.MarketIndex mi ON v.EntityId = mi.MarketIndexId WHERE v.EntityTypeId = 3 AND v.ValuationDate >= @qtdDate AND v.FrequencyId = 3 \n",
    "            GROUP BY mi.MarketIndexName, v.EntityId \n",
    "            ORDER BY QTD_Performance DESC;\"\"\"},\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L12-v2\")\n",
    "\n",
    "# Select examples using semantic similarity\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples,\n",
    "    embeddings,\n",
    "    FAISS,\n",
    "    k=5,\n",
    "    input_keys=[\"input\"],\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=PromptTemplate.from_template(\"User input: {input}\\nSQL query: {query}\"),\n",
    "    input_variables=[\"input\", \"dialect\", \"top_k\"],\n",
    "    prefix=system_prefix,\n",
    "    suffix=system_suffix,\n",
    ")\n",
    "\n",
    "full_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate(prompt=prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "        MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create SQL Agent\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)  # Use the SQLDatabase instance here\n",
    "agent_executor = create_sql_agent(llm=llm, toolkit=toolkit, extra_tools=[custom_tool], prompt=full_prompt, verbose=True, agent_type=\"openai-tools\", handle_parsing_errors=True)\n",
    "\n",
    "\n",
    "# Define Flask API route\n",
    "# @app.route('/query', methods=['GET'])\n",
    "# def query_database():\n",
    "#     query = request.args.get('query')\n",
    "\n",
    "#     if not query:\n",
    "#         return jsonify({\"error\": \"No query provided\"}), 400\n",
    "\n",
    "#     try:\n",
    "#         result = agent_executor.invoke(query)\n",
    "#         return jsonify({\"result\": result})\n",
    "#     except Exception as e:\n",
    "#         return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "@traceable\n",
    "@app.route('/', methods=['POST'])\n",
    "def query_database():\n",
    "    try:\n",
    "        # Parse JSON input from the request\n",
    "        data = request.get_json()\n",
    "\n",
    "        if not data or 'question' not in data:\n",
    "            return jsonify({\"error\": \"No query provided. Please include a 'query' field in the JSON body.\"}), 400\n",
    "\n",
    "        query = data['question']\n",
    "\n",
    "        # Invoke the agent to get the SQL query results\n",
    "        result = agent_executor.invoke(query)\n",
    "\n",
    "        # Assuming the result is already in a structured JSON format, return it directly\n",
    "        return jsonify({\"result\": result})\n",
    "\n",
    "    except Exception as e:\n",
    "        # Catch any errors and return as JSON\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "\n",
    "if _name_ == '__main__':\n",
    "    app.run(debug=False, host='0.0.0.0' ,port=5000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vizualation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
